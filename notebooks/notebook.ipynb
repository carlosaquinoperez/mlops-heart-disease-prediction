{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0acc4ba2",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c65d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa66ed4",
   "metadata": {},
   "source": [
    "**Data Dictionary**\n",
    "\n",
    "This section clarifies the meaning of our columns, especially the coded features.\n",
    "\n",
    "* **age_years**: Age of the patient (in years).\n",
    "* **gender**: 1: Male, 2: Female\n",
    "* **height_cm**: Height in centimeters.\n",
    "* **weight_kg**: Weight in kilograms.\n",
    "* **systolic_bp**: Systolic blood pressure (the \"upper\" number).\n",
    "* **diastolic_bp**: Diastolic blood pressure (the \"lower\" number).\n",
    "* **cholesterol**: 1: Normal, 2: Above Normal, 3: Well Above Normal\n",
    "* **glucose**: 1: Normal, 2: Above Normal, 3: Well Above Normal\n",
    "* **is_smoker**: 0: No, 1: Yes\n",
    "* **is_alcoholic**: 0: No, 1: Yes\n",
    "* **is_active**: 0: No, 1: Yes\n",
    "* **target**: 0: No cardiovascular disease, 1: Presence of cardiovascular disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b855e11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cardio_train.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfcba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for better clarity\n",
    "column_mapping = {\n",
    "    'age': 'age_days',\n",
    "    'height': 'height_cm',\n",
    "    'weight': 'weight_kg',\n",
    "    'ap_hi': 'systolic_bp',\n",
    "    'ap_lo': 'diastolic_bp',\n",
    "    'gluc': 'glucose',\n",
    "    'smoke': 'is_smoker',\n",
    "    'alco': 'is_alcoholic',\n",
    "    'active': 'is_active',\n",
    "    'cardio': 'target'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb6cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert age from days to years\n",
    "df['age_years'] = (df['age_days'] / 365.25).round().astype(int)\n",
    "\n",
    "df = df.drop(columns=['id', 'age_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899c6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = [\n",
    "    'age_years',\n",
    "    'gender',\n",
    "    'height_cm',\n",
    "    'weight_kg',\n",
    "    'systolic_bp',\n",
    "    'diastolic_bp',\n",
    "    'cholesterol',\n",
    "    'glucose',\n",
    "    'is_smoker',\n",
    "    'is_alcoholic',\n",
    "    'is_active',\n",
    "    'target'\n",
    "]\n",
    "\n",
    "df = df[final_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6b0807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_years</th>\n",
       "      <th>gender</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>is_smoker</th>\n",
       "      <th>is_alcoholic</th>\n",
       "      <th>is_active</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_years  gender  height_cm  weight_kg  systolic_bp  diastolic_bp  \\\n",
       "0         50       2        168       62.0          110            80   \n",
       "1         55       1        156       85.0          140            90   \n",
       "2         52       1        165       64.0          130            70   \n",
       "3         48       2        169       82.0          150           100   \n",
       "4         48       1        156       56.0          100            60   \n",
       "\n",
       "   cholesterol  glucose  is_smoker  is_alcoholic  is_active  target  \n",
       "0            1        1          0             0          1       0  \n",
       "1            3        1          0             0          1       1  \n",
       "2            3        1          0             0          0       1  \n",
       "3            1        1          0             0          1       1  \n",
       "4            1        1          0             0          0       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5931ac5",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d18904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable Distribution (0 = No Disease, 1 = Disease):\n",
      "target\n",
      "0    0.5003\n",
      "1    0.4997\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Variable Distribution (0 = No Disease, 1 = Disease):\")\n",
    "target_distribution = df['target'].value_counts(normalize=True)\n",
    "print(target_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1938b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6612fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'gender', \n",
    "    'cholesterol', \n",
    "    'glucose', \n",
    "    'is_smoker', \n",
    "    'is_alcoholic', \n",
    "    'is_active'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'age_years', \n",
    "    'height_cm', \n",
    "    'weight_kg', \n",
    "    'systolic_bp', \n",
    "    'diastolic_bp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0911cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Mutual Information (Categorical Features) ---\n",
      "cholesterol     0.025351\n",
      "glucose         0.004223\n",
      "is_active       0.000636\n",
      "is_smoker       0.000120\n",
      "gender          0.000033\n",
      "is_alcoholic    0.000027\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "--- Correlation (Numerical Features) ---\n",
      "age_years       0.237802\n",
      "weight_kg       0.181660\n",
      "diastolic_bp    0.065719\n",
      "systolic_bp     0.054475\n",
      "height_cm       0.010821\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Mutual Information (for Categorical) ---\n",
    "# This tells us how much \"information\" a feature gives us about the target\n",
    "\n",
    "def mutual_info_target_score(series):\n",
    "    return mutual_info_score(series, df['target'])\n",
    "\n",
    "print(\"--- Mutual Information (Categorical Features) ---\")\n",
    "# We apply this function to all categorical columns\n",
    "mi_scores = df[categorical_features].apply(mutual_info_target_score)\n",
    "print(mi_scores.sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- 2. Correlation (for Numerical) ---\n",
    "# This tells us how linearly related a feature is to the target\n",
    "# We use .abs() because a strong negative correlation (-0.8) is just\n",
    "# as important as a strong positive one (0.8).\n",
    "\n",
    "print(\"--- Correlation (Numerical Features) ---\")\n",
    "correlation_scores = df[numerical_features].corrwith(df['target']).abs()\n",
    "print(correlation_scores.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d4c995",
   "metadata": {},
   "source": [
    "## 3. Validation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa435a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5145e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data ---\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69651684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, split the 80% (full_train) into 75% (train) and 25% (validation)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75eeef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:   42000\n",
      "Validation set size: 14000\n",
      "Test set size:       14000\n"
     ]
    }
   ],
   "source": [
    "# get the 'target' column (our y) from each dataframe\n",
    "y_train = df_train['target'].values\n",
    "y_val = df_val['target'].values\n",
    "y_test = df_test['target'].values\n",
    "\n",
    "# delete the 'target' column from the feature dataframes\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "del df_val['target']\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "del df_test['target']\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Check the results ---\n",
    "print(f\"Training set size:   {len(df_train)}\")\n",
    "print(f\"Validation set size: {len(df_val)}\")\n",
    "print(f\"Test set size:       {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4780cd3",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d0b38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32bf4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "dv = DictVectorizer(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4efd2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our training data (df_train) into a dictionary format\n",
    "train_dicts = df_train[categorical_features + numerical_features].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ccb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data to create the feature matrix X_train\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8194cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our validation data (df_val) into a dictionary format\n",
    "val_dicts = df_val[categorical_features + numerical_features].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c95b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the validation data using the *same* fitted vectorizer\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2435e5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape (train): (42000, 12)\n",
      "New Feature Matrix shape (X_train): (42000, 11)\n",
      "\n",
      "Feature names created by DictVectorizer:\n",
      "['age_years' 'cholesterol' 'diastolic_bp' 'gender' 'glucose' 'height_cm'\n",
      " 'is_active' 'is_alcoholic' 'is_smoker' 'systolic_bp']\n"
     ]
    }
   ],
   "source": [
    "# Check the results\n",
    "print(f\"Original DataFrame shape (train): {df_train.shape}\")\n",
    "print(f\"New Feature Matrix shape (X_train): {X_train.shape}\")\n",
    "print(\"\\nFeature names created by DictVectorizer:\")\n",
    "print(dv.get_feature_names_out()[:10]) # Print first 10 feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c835db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50.,   1.,  80., ...,   0., 150.,  84.],\n",
       "       [ 61.,   1.,  80., ...,   1., 150.,  78.],\n",
       "       [ 52.,   1.,  80., ...,   0., 120.,  65.],\n",
       "       ...,\n",
       "       [ 61.,   1.,  80., ...,   0., 120.,  70.],\n",
       "       [ 48.,   1.,  80., ...,   0., 120.,  53.],\n",
       "       [ 42.,   1.,  90., ...,   0., 130.,  80.]], shape=(42000, 11))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c29170",
   "metadata": {},
   "source": [
    "## 5. Model Training: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a42772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27f077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ad0bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT the scaler ONLY on the training data (X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12484f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver='lbfgs' as it's the modern default\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80329b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train (fit) the model on our 'X_train' feature matrix\n",
    "# and our 'y_train' target vector\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4037795",
   "metadata": {},
   "source": [
    "## 6. Model evaluation (Validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c118267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c68afdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Model (Logistic Regression) ---\n",
      "Validation Accuracy: 71.83%\n"
     ]
    }
   ],
   "source": [
    "# scaled validation features (X_val_scaled)\n",
    "y_pred_val = model.predict(X_val_scaled)\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "print(f\"--- Baseline Model (Logistic Regression) ---\")\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f7b85",
   "metadata": {},
   "source": [
    "## 7. Model training: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "332b338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fc7106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model training complete!\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Random Forest model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdf3db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:     70.31%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Random Forest Model\n",
    "y_pred_rf = rf_model.predict(X_val_scaled)\n",
    "rf_accuracy = accuracy_score(y_val, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Accuracy:     {rf_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e8c97",
   "metadata": {},
   "source": [
    "## 8. Final model selection and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e188a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Final Model Training ---\n",
      "Training the full pipeline (this may take a moment)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline training complete!\n",
      "Final Pipeline saved to: model.bin\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "print(\"--- Starting Final Model Training ---\")\n",
    "\n",
    "# --- 1. Define Categorical and Numerical Features ---\n",
    "categorical_features = [\n",
    "    'gender', 'cholesterol', 'glucose', 'is_smoker', 'is_alcoholic', 'is_active'\n",
    "]\n",
    "numerical_features = [\n",
    "    'age_years', 'height_cm', 'weight_kg', 'systolic_bp', 'diastolic_bp'\n",
    "]\n",
    "\n",
    "# --- 2. Combine Train + Validation data for final training ---\n",
    "df_full_train_final = pd.concat([df_train, df_val])\n",
    "y_full_train_final = pd.concat([pd.Series(y_train), pd.Series(y_val)])\n",
    "\n",
    "\n",
    "# --- 3. Define Preprocessing Pipeline ---\n",
    "\n",
    "# Helper function for ColumnTransformer\n",
    "def to_dicts(df):\n",
    "    return df.to_dict(orient='records')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num_scaler', StandardScaler(), numerical_features),\n",
    "        ('cat_encoder', make_pipeline(\n",
    "            FunctionTransformer(to_dicts),\n",
    "            DictVectorizer(sparse=False)\n",
    "        ), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# --- 4. Create the Final End-to-End Pipeline ---\n",
    "#\n",
    "# Step 1: Run the preprocessor\n",
    "# Step 2: Run the Logistic Regression model\n",
    "final_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)\n",
    ")\n",
    "\n",
    "# --- 5. Train the Final Pipeline ---\n",
    "print(\"Training the full pipeline (this may take a moment)...\")\n",
    "final_pipeline.fit(df_full_train_final, y_full_train_final)\n",
    "print(\"Pipeline training complete!\")\n",
    "\n",
    "# --- 6. Save the Pipeline to a File ---\n",
    "#\n",
    "output_file = 'model.bin'\n",
    "\n",
    "with open(output_file, 'wb') as f_out:\n",
    "    pickle.dump(final_pipeline, f_out)\n",
    "\n",
    "print(f\"Final Pipeline saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
